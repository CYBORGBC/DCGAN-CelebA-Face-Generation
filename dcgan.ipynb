{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(None, 128, 128, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 105\u001b[0m\n\u001b[0;32m    103\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    104\u001b[0m gan_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m,))\n\u001b[1;32m--> 105\u001b[0m gan_output \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m gan \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(gan_input, gan_output)\n\u001b[0;32m    107\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-4\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(None, 128, 128, 3)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Path to your local CelebA dataset folder\n",
    "DATASET_PATH = \"celeba-dataset\"\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = (64, 64)\n",
    "\n",
    "# Load dataset from directory\n",
    "def load_dataset():\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        DATASET_PATH,\n",
    "        label_mode=None,  # No labels needed for GAN\n",
    "        image_size=IMG_SIZE,  # Resize images to 64x64\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    dataset = dataset.map(lambda x: (tf.cast(x, tf.float32) - 127.5) / 127.5)  # Normalize [-1,1]\n",
    "    return dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset()\n",
    "\n",
    "def build_generator():\n",
    "    inputs = tf.keras.layers.Input(shape=(100,))\n",
    "    x = tf.keras.layers.Dense(8 * 8 * 512, use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.Reshape((8, 8, 512))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding=\"same\", activation=\"tanh\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def build_discriminator():\n",
    "    inputs = tf.keras.layers.Input(shape=(64, 64, 3))\n",
    "    x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "\n",
    "def train_dcgan(epochs=50):\n",
    "    seed = tf.random.normal([16, 100])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for real_images in dataset:\n",
    "            noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "            generated_images = generator(noise)\n",
    "            \n",
    "            real_labels = tf.ones((BATCH_SIZE, 1))\n",
    "            fake_labels = tf.zeros((BATCH_SIZE, 1))\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "            \n",
    "            noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "            g_loss = gan.train_on_batch(noise, tf.ones((BATCH_SIZE, 1)))\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - D Loss: {d_loss_real + d_loss_fake:.4f}, G Loss: {g_loss:.4f}\")\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow((predictions[i] + 1) / 2)\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(f\"generated_image_epoch_{epoch}.png\")\n",
    "    plt.show()\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = tf.keras.models.Model(gan_input, gan_output)\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "\n",
    "train_dcgan(epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
